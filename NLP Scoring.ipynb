{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_df=pd.read_csv('Expp-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "descsss=[]\n",
    "for i in range(Exp_df.shape[0]):\n",
    "    descsss.append(Exp_df['Final_desc'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Smart Interns who possess strong technical development skills and knowledge of advanced topics in Data Science, Machine Learning & Artificial IntelligenceAn ideal candidate would be An individual who is passionate about Data Science, Machine Learning & Artificial Intelligence and build content in this spaceResponsible for building quality content - social posts and blogs in Data Science Moderate a vibrant Data Science community'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string='''Smart Interns who possess strong technical development skills and knowledge of advanced topics in Data Science, Machine Learning & Artificial IntelligenceAn ideal candidate would be An individual who is passionate about Data Science, Machine Learning & Artificial Intelligence and build content in this spaceResponsible for building quality content - social posts and blogs in Data Science Moderate a vibrant Data Science community'''\n",
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "puncs=string.punctuation\n",
    "\n",
    "stops=stopwords.words('english')\n",
    "\n",
    "from re import sub\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SparseTermSimilarityMatrix\n",
    "from gensim.similarities import SoftCosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.WordEmbeddingSimilarityIndex object at 0x000001BC9D386688>\n"
     ]
    }
   ],
   "source": [
    "# Load the model: this is a big file, can take a while to download and open\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")    \n",
    "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
    "#print(similarity_index)\n",
    "\n",
    "query_string = input_string\n",
    "\n",
    "\n",
    "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
    "def preprocess(doc):\n",
    "    # Tokenize, clean up input document string\n",
    "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
    "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
    "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
    "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
    "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stops and token not in puncs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the documents, including the query string\n",
    "corpus = [preprocess(document) for document in descsss]\n",
    "query = preprocess(query_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15, 0.1196984779992493), (26, 0.0894406090885117), (37, 0.18245768556515124), (42, 0.18245768556515124), (63, 0.28411726054275444), (67, 0.09122884278257562), (93, 0.1196984779992493), (94, 0.09122884278257562), (117, 0.07102931513568861), (215, 0.1196984779992493), (223, 0.1196984779992493), (267, 0.1196984779992493), (369, 0.1196984779992493), (396, 0.33673528172562), (397, 0.16836764086281), (398, 0.16836764086281), (399, 0.16836764086281), (400, 0.33673528172562), (401, 0.16836764086281), (402, 0.16836764086281), (403, 0.16836764086281), (404, 0.16836764086281), (405, 0.16836764086281), (406, 0.16836764086281), (407, 0.16836764086281), (408, 0.16836764086281), (409, 0.16836764086281), (410, 0.16836764086281), (411, 0.16836764086281), (412, 0.16836764086281), (413, 0.16836764086281), (414, 0.16836764086281), (415, 0.16836764086281)]\n"
     ]
    }
   ],
   "source": [
    "# Build the term dictionary, TF-idf model\n",
    "dictionary = Dictionary(corpus+[query])\n",
    "#print(dictionary.token2id)\n",
    "tfidf = TfidfModel(dictionary=dictionary)\n",
    "#print(tfidf)\n",
    "# Create the term similarity matrix.  \n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)\n",
    "#print(similarity_matrix)\n",
    "query_tf = tfidf[dictionary.doc2bow(query)]\n",
    "#print(query_tf)\n",
    "index = SoftCosineSimilarity(\n",
    "            tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
    "            similarity_matrix)\n",
    "doc_similarity_scores = index[query_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similarity_scores=doc_similarity_scores*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_similarity_scores=[round(i) for i in doc_similarity_scores]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_df['Rank']=doc_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_df.to_csv('Final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
